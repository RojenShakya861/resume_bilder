{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lOXtVkUAMDp",
        "outputId": "ddc0bb38-ae82-4bfc-9f63-2942a4c147af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n",
            "Created sample dataset\n",
            "Dataset loaded with 15 samples and 44 unique skills\n",
            "Training model...\n",
            "Saving model and encoder...\n",
            "Model training completed successfully!\n",
            "\n",
            "Top 10 most important skills:\n",
            "           skill  importance\n",
            "41           SQL        0.50\n",
            "2            Git        0.25\n",
            "26        Docker        0.25\n",
            "0        Tableau        0.00\n",
            "4           Java        0.00\n",
            "5     TypeScript        0.00\n",
            "6     JavaScript        0.00\n",
            "7   React Native        0.00\n",
            "8          Linux        0.00\n",
            "9         Spring        0.00\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "def load_dataset():\n",
        "    \"\"\"Load and preprocess the skills dataset\"\"\"\n",
        "    print(\"Loading dataset...\")\n",
        "\n",
        "    # Create sample dataset if it doesn't exist\n",
        "    if not os.path.exists('content/skills_dataset.csv'):\n",
        "        os.makedirs('data', exist_ok=True)\n",
        "\n",
        "        # Create sample data\n",
        "        data = {\n",
        "            'job_title': [\n",
        "                'Software Developer', 'Software Developer', 'Software Developer',\n",
        "                'Data Scientist', 'Data Scientist', 'Data Scientist',\n",
        "                'Web Developer', 'Web Developer', 'Web Developer',\n",
        "                'DevOps Engineer', 'DevOps Engineer', 'DevOps Engineer',\n",
        "                'Mobile Developer', 'Mobile Developer', 'Mobile Developer'\n",
        "            ],\n",
        "            'skills': [\n",
        "                ['Python', 'JavaScript', 'SQL', 'Git', 'REST API'],\n",
        "                ['Java', 'Spring', 'SQL', 'Git', 'Maven'],\n",
        "                ['C#', '.NET', 'SQL', 'Git', 'Azure'],\n",
        "                ['Python', 'R', 'SQL', 'Statistics', 'Machine Learning'],\n",
        "                ['Python', 'SQL', 'Data Analysis', 'Statistics', 'Tableau'],\n",
        "                ['Python', 'SQL', 'Deep Learning', 'TensorFlow', 'PyTorch'],\n",
        "                ['HTML', 'CSS', 'JavaScript', 'React', 'Node.js'],\n",
        "                ['HTML', 'CSS', 'JavaScript', 'Vue.js', 'PHP'],\n",
        "                ['HTML', 'CSS', 'JavaScript', 'Angular', 'TypeScript'],\n",
        "                ['Linux', 'Docker', 'Kubernetes', 'AWS', 'CI/CD'],\n",
        "                ['Linux', 'Docker', 'Jenkins', 'Terraform', 'Ansible'],\n",
        "                ['Linux', 'Docker', 'Azure', 'Puppet', 'Shell Scripting'],\n",
        "                ['Java', 'Kotlin', 'Android', 'REST API', 'Git'],\n",
        "                ['Swift', 'iOS', 'Xcode', 'REST API', 'Git'],\n",
        "                ['React Native', 'JavaScript', 'Mobile UI', 'REST API', 'Git']\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        # Convert to DataFrame\n",
        "        df = pd.DataFrame(data)\n",
        "        df.to_csv('/content/skills_dataset.csv', index=False)\n",
        "        print(\"Created sample dataset\")\n",
        "\n",
        "    # Load the dataset\n",
        "    df = pd.read_csv('/content/skills_dataset.csv')\n",
        "\n",
        "    # Convert skills string to list\n",
        "    df['skills'] = df['skills'].apply(eval)\n",
        "\n",
        "    # Get all unique skills\n",
        "    all_skills = set()\n",
        "    for skills in df['skills']:\n",
        "        all_skills.update(skills)\n",
        "\n",
        "    # Create binary features for each skill\n",
        "    for skill in all_skills:\n",
        "        df[skill] = df['skills'].apply(lambda x: 1 if skill in x else 0)\n",
        "\n",
        "    # Prepare features and target\n",
        "    X = df.drop(['job_title', 'skills'], axis=1)\n",
        "    y = df['job_title']\n",
        "\n",
        "    # Encode job titles\n",
        "    label_encoder = LabelEncoder()\n",
        "    y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "    print(f\"Dataset loaded with {len(df)} samples and {len(all_skills)} unique skills\")\n",
        "    return X, y_encoded, label_encoder\n",
        "\n",
        "def train_model():\n",
        "    \"\"\"Train and save the decision tree model\"\"\"\n",
        "    try:\n",
        "        # Load and preprocess data\n",
        "        X, y, label_encoder = load_dataset()\n",
        "\n",
        "        # Create and train the model\n",
        "        print(\"Training model...\")\n",
        "        model = DecisionTreeClassifier(random_state=42)\n",
        "        model.fit(X, y)\n",
        "\n",
        "        # Create models directory if it doesn't exist\n",
        "        os.makedirs('models', exist_ok=True)\n",
        "\n",
        "        # Save the model and label encoder\n",
        "        print(\"Saving model and encoder...\")\n",
        "        joblib.dump(model, 'models/skill_model.joblib')\n",
        "        joblib.dump(label_encoder, 'models/label_encoder.joblib')\n",
        "\n",
        "        print(\"Model training completed successfully!\")\n",
        "\n",
        "        # Print feature importance\n",
        "        feature_importance = pd.DataFrame({\n",
        "            'skill': X.columns,\n",
        "            'importance': model.feature_importances_\n",
        "        }).sort_values('importance', ascending=False)\n",
        "\n",
        "        print(\"\\nTop 10 most important skills:\")\n",
        "        print(feature_importance.head(10))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during model training: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train_model()"
      ]
    }
  ]
}